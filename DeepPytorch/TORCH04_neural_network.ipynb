{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TORCH04. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter(torch.Tensor):\n",
    "    \"\"\"\n",
    "    A kind of Tensor that is to be considered a module parameter.\n",
    "    \"\"\"\n",
    "    def __new__(cls, data=None, requires_grad=True):\n",
    "        if data is None:\n",
    "            data = torch.Tensor()\n",
    "        return torch.Tensor._make_subclass(cls, data, requires_grad)\n",
    "    \n",
    "    def __deepcopy__(self, memo):\n",
    "        if id(self) in memo:\n",
    "            return memo[id(self)]\n",
    "        else:\n",
    "            result = type(self)(self.data.clone(memory_format=torch.preserve_format),\n",
    "                                self.requires_grad)\n",
    "            memo[id(self)] = result\n",
    "            return result\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'Parameter containing:\\n' + super(Parameter, self).__repr__()\n",
    "    \n",
    "    def __reduce_ex__(self, proto):\n",
    "        \"\"\"\n",
    "        < 자신의 객체 피클링하기 >\n",
    "        \n",
    "        `__reduce__(self)`: 확장 타입(즉, 파이썬의 C API를 사용하여 구현된 타입)을\n",
    "            정의할 때 파이썬에서 피클링하려는 경우 피클링 방법을 지정.\n",
    "            `__reduce__()`는 정의도니 객체가 피클될 때 호출.\n",
    "            파이썬이 찾고 피클하는 전역 이름을 나타내는 문자열 또는 튜플을 반활할 수 있음.\n",
    "            튜플은 2~5개 요소를 포함\n",
    "                (\n",
    "                    객체를 다시 생성하기 위해 호출되는 호출 가능 객체,\n",
    "                    호출 가능 객체에 대한 인수의 튜플,\n",
    "                    `__setstate__`에 전달될 상태 (선택 사항),\n",
    "                    피클링될 리스트 항목을 생성하는 반복자 (선택 사항),\n",
    "                    피클링할 딕셔너리 항목을 생성하는 반복자 (선택 사항)\n",
    "                )\n",
    "                \n",
    "        `__reduce_ex__(self)`: 호환성을 위해 존재.\n",
    "        \"\"\"\n",
    "        # See Note [Don't serialize hooks]\n",
    "        return (\n",
    "            torch.utils._rebuild_parameter,\n",
    "            (self.data, self.requires_grad, OrderedDict())\n",
    "        )\n",
    "    \n",
    "import math\n",
    "\n",
    "def kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu'):\n",
    "    \"\"\"He initialization\"\"\"\n",
    "    fan = _calculate_correct_fan(tensor, mode)\n",
    "    gain = calculate_gain(nonlinearity, a)\n",
    "    std = gain / math.sqrt(fan)\n",
    "    bound = math.sqrt(3.0) * std\n",
    "    with torch.no_grad():\n",
    "        return tensor.uniform_(-bound, bound)\n",
    "    \n",
    "def _calculate_correct_fan(tensor, mode):\n",
    "    mode = mode.lower()\n",
    "    valid_modes = ['fan_in', 'fan_out']\n",
    "    if mode not in valid_modes:\n",
    "        raise ValueError(\"Mode {} not supported, please use one of {}\".format(mode, valid_modes))\n",
    "        \n",
    "    fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)\n",
    "    return fan_in if mode == 'fan_in' else fan_out\n",
    "\n",
    "def _calculate_fan_in_and_fan_out(tensor):\n",
    "    dimensions = tensor.dim()\n",
    "    if dimensions < 2:\n",
    "        raise ValueError(\"Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\")\n",
    "        \n",
    "    num_input_fmaps = tensor.size(1)\n",
    "    num_output_fmaps = tensor.size(0)\n",
    "    receptive_field_size = 1\n",
    "    if tensor.dim() > 2:\n",
    "        receptive_field_size = tensor[0][0].numel()\n",
    "    fan_in = num_input_fmaps * receptive_field_size\n",
    "    fan_out = num_output_fmaps * receptive_field_size\n",
    "    \n",
    "    return fan_in, fan_out\n",
    "\n",
    "def calculate_gain(nonlinearity, param=None):\n",
    "    linear_fns = ['linear', 'conv1d', 'conv2d', 'conv3d', 'conv_transpose1d', 'conv_transpose2d', 'conv_transpose3d']\n",
    "    if nonlinearity in linear_fns or nonlinearity == 'sigmoid':\n",
    "        return 1\n",
    "    elif nonlinearity == 'tanh':\n",
    "        return 5.0 / 3\n",
    "    elif nonlinearity == 'relu':\n",
    "        return math.sqrt(2.0)\n",
    "    elif nonlinearity == 'leaky_relu':\n",
    "        if param is None:\n",
    "            negative_slope = 0.01\n",
    "        elif not isinstance(param, bool) and isinstance(param, int) or isinstance(param, float):\n",
    "            negative_slope = param\n",
    "        else:\n",
    "            raise ValueError(\"negative_slope {} not a valid number\".format(param))\n",
    "        return math.sqrt(2.0 / (1 + negative_slope ** 2))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported nonlinearity {}\".format(nonlinearity))\n",
    "        \n",
    "from torch._six import container_abcs\n",
    "from itertools import repeat\n",
    "\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, container_abcs.Iterable):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse\n",
    "\n",
    "_single = _ntuple(1)\n",
    "_pair = _ntuple(2)\n",
    "_triple = _ntuple(3)\n",
    "_quadruple = _ntuple(4)\n",
    "\n",
    "\n",
    "def _list_with_default(out_size, defaults):\n",
    "    if isinstance(out_size, int):\n",
    "        return out_size\n",
    "    if len(defaults) <= len(out_size):\n",
    "        raise ValueError('Input dimension should be at least {}'.format(len(out_size) + 1))\n",
    "    return [v if v is not None else d for v, d in zip(out_size, defaults[-len(out_size):])]\n",
    "\n",
    "def uniform_(tensor, a=0., b=1.):\n",
    "    return _no_grad_uniform_(tensor, a, b)\n",
    "\n",
    "def _no_grad_uniform_(tensor, a, b):\n",
    "    with torch.no_grad():\n",
    "        return tensor.uniform_(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleModule:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._parameters = OrderedDict()\n",
    "        self._buffers = OrderedDict()\n",
    "        self._modules = OrderedDict()\n",
    "        \n",
    "    def __getattr__(self, name):\n",
    "        if '_parameters' in self.__dict__:\n",
    "            _parameters = self.__dict__['_parameters']\n",
    "            if name in _parameters:\n",
    "                return _parameters[name]\n",
    "        if '_buffers' in self.__dict__:\n",
    "            _buffers = self.__dict__['_buffers']\n",
    "            if name in _buffers:\n",
    "                return _buffers[name]\n",
    "        if '_modules' in self.__dict__:\n",
    "            modules = self.__dict__['_modules']\n",
    "            if name in modules:\n",
    "                return modules[name]\n",
    "        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
    "            type(self).__name__, name))\n",
    "        \n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, Parameter):\n",
    "            self.register_parameter(name, value)\n",
    "        elif isinstance(value, simpleModule):\n",
    "            modules = self.__dict__.get('_modules')\n",
    "            modules[name] = value\n",
    "        else:\n",
    "            buffers = self.__dict__.get('_buffers')\n",
    "            if (buffers is not None) and (name in buffers):\n",
    "                if (value is not None) and (not isinstance(value, torch.Tensor)):\n",
    "                    raise TypeError('Nope.')\n",
    "                    buffers[name] = value\n",
    "            else:\n",
    "                object.__setattr__(self, name, value)\n",
    "        \n",
    "    def register_parameter(self, name, value):\n",
    "        self._parameters[name] = value\n",
    "        \n",
    "class simple_ConvNd(simpleModule):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
    "                 padding, dilation, transposed, output_padding,\n",
    "                 groups, bias, padding_mode):\n",
    "        super(simple_ConvNd, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.transposed = transposed\n",
    "        self.output_padding = output_padding\n",
    "        self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "        if transposed:\n",
    "            self.weight = Parameter(torch.Tensor(\n",
    "                in_channels, out_channels // groups, *kernel_size))\n",
    "        else:\n",
    "            self.weight = Parameter(torch.Tensor(\n",
    "                out_channels, in_channels // groups, *kernel_size))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = _calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            uniform_(self.bias, -bound, bound)\n",
    "            \n",
    "    def extra_repr(self):\n",
    "        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n",
    "             ', stride={stride}')\n",
    "        if self.padding != (0,) * len(self.padding):\n",
    "            s += ', padding={padding}'\n",
    "        if self.dilation != (1,) * len(self.dilation):\n",
    "            s += ', dilation={dilation}'\n",
    "        if self.output_padding != (0,) * len(self.output_padding):\n",
    "            s += ', output_padding={output_padding}'\n",
    "        if self.groups != 1:\n",
    "            s += ', groups={groups}'\n",
    "        if self.bias is None:\n",
    "            s += ', bias=False'\n",
    "        if self.padding_mode != 'zeros':\n",
    "            s += ', padding_mode={padding_mode}'\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(simple_ConvNd, self).__setstate__(state)\n",
    "        if not hasattr(self, 'padding_mode'):\n",
    "            self.padding_mode = 'zeros'\n",
    "            \n",
    "class simpleConv2d(simple_ConvNd):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1,\n",
    "                 bias=True, padding_mode='zeros'):\n",
    "        kernel_size = _pair(kernel_size)\n",
    "        stride = _pair(stride)\n",
    "        padding = _pair(padding)\n",
    "        dilation = _pair(dilation)\n",
    "        super(simpleConv2d, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation,\n",
    "            False, _pair(0), groups, bias, padding_mode)\n",
    "\n",
    "    def conv2d_forward(self, input, weight):\n",
    "        if self.padding_mode == 'circular':\n",
    "            expanded_padding = ((self.padding[1] + 1) // 2, self.padding[1] // 2,\n",
    "                                (self.padding[0] + 1) // 2, self.padding[0] // 2)\n",
    "            return F.conv2d(F.pad(input, expanded_padding, mode='circular'),\n",
    "                            weight, self.bias, self.stride,\n",
    "                            _pair(0), self.dilation, self.groups)\n",
    "        return F.conv2d(input, weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv2d_forward(input, self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNet(simpleModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.conv1 = simpleConv2d(1, 6, 2)\n",
    "        self.conv2 = simpleConv2d(6, 16, 3)\n",
    "        self.conv3 = simpleConv2d(16, 32, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max Pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.avg_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        return x\n",
    "    \n",
    "net = CustomNet()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomNet at 0x20f4f501470>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class Module:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._parameters = OrderedDict()\n",
    "        self._buffers = OrderedDict()\n",
    "        self._modules = OrderedDict()\n",
    "        \n",
    "    def __setattr__(self, name, value):\n",
    "        def remove_from(*dict):\n",
    "            for d in dict:\n",
    "                if name in d:\n",
    "                    del d[name]\n",
    "                    \n",
    "        # Parameter인지\n",
    "        params = self.__dict__.get('_parameters')\n",
    "        if isinstance(value, Parameter):\n",
    "            if params is None:\n",
    "                raise AttributeError(\n",
    "                    \"cannot assign parameters before Module.__init__() call\")\n",
    "            remove_from(self.__dict__, self._buffers, self._modules)\n",
    "            self.register_parameter(name, value)\n",
    "        elif params is not None and name in params:\n",
    "            if value is not None:\n",
    "                raise TypeError(\"cannot assign '{}' as parameter '{}' \"\n",
    "                                \"(torch.nn.Parameter or None expected)\"\n",
    "                                .format(torch.typename(value), name))\n",
    "            self.register_parameter(name, value)\n",
    "        else:\n",
    "            # sub-Module인지\n",
    "            modules = self.__dict__.get('_modules')\n",
    "            if isinstance(value, Module):\n",
    "                if modules is None:\n",
    "                    raise AttributeError(\n",
    "                        \"cannot assign module before Module.__init__() call\")\n",
    "                remove_from(self.__dict__, self._parameters, self._buffers)\n",
    "                modules[name] = value\n",
    "            elif (modules is not None) and (name in modules):\n",
    "                if value is not None:\n",
    "                    raise TypeError(\"cannot assign '{}' as child module '{}' \"\n",
    "                                    \"(torch.nn.Module or None expected)\"\n",
    "                                    .format(torch.typename(value), name))\n",
    "                modules[name] = value\n",
    "            else:\n",
    "                # Buffer인지\n",
    "                buffers = self.__dict__.get('_buffers')\n",
    "                if buffers is not None and name in buffers:\n",
    "                    if value is not None and not isinstance(value, torch.Tensor):\n",
    "                        raise TypeError(\"cannot assign '{}' as buffer '{}' \"\n",
    "                                        \"(torch.Tensor or None expected)\"\n",
    "                                        .format(torch.typename(value), name))\n",
    "                    buffers[name] = value\n",
    "                else:\n",
    "                    object.__setattr__(self, name, value)\n",
    "                    \n",
    "    def register_parameter(self, name, param):\n",
    "        # 예외 처리\n",
    "        if '_parameters' not in self.__dict__:\n",
    "            raise AttributeError(\n",
    "                \"cannot assign parameter before Module.__init__() call\")\n",
    "\n",
    "        elif not isinstance(name, torch._six.string_classes):\n",
    "            raise TypeError(\"parameter name should be a string. \"\n",
    "                            \"Got {}\".format(torch.typename(name)))\n",
    "        elif '.' in name:\n",
    "            raise KeyError(\"parameter name can't contain \\\".\\\"\")\n",
    "        elif name == '':\n",
    "            raise KeyError(\"parameter name can't be empty string \\\"\\\"\")\n",
    "        elif hasattr(self, name) and name not in self._parameters:\n",
    "            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
    "\n",
    "        if param is None:\n",
    "            self._parameters[name] = None\n",
    "        elif not isinstance(param, Parameter):\n",
    "            raise TypeError(\"cannot assign '{}' object to parameter '{}' \"\n",
    "                            \"(torch.nn.Parameter or None required)\"\n",
    "                            .format(torch.typename(param), name))\n",
    "        elif param.grad_fn:\n",
    "            raise ValueError(\n",
    "                \"Cannot assign non-leaf Tensor to parameter '{0}'. Model \"\n",
    "                \"parameters must be created explicitly. To express '{0}' \"\n",
    "                \"as a function of another Tensor, compute the value in \"\n",
    "                \"the forward() method.\".format(name))\n",
    "        # 할당\n",
    "        else:\n",
    "            self._parameters[name] = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ConvNd(Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
    "                 padding, dilation, transposed, output_padding,\n",
    "                 groups, bias, padding_mode):\n",
    "        super(_ConvNd, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.weight = Parameter(torch.Tensor(\n",
    "            in_channels, out_channels // groups, *kernel_size))\n",
    "        print(self.weight)\n",
    "        self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = _calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            uniform_(self.bias, -bound, bound)\n",
    "            \n",
    "    def extra_repr(self):\n",
    "        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n",
    "             ', stride={stride}')\n",
    "        if self.padding != (0,) * len(self.padding):\n",
    "            s += ', padding={padding}'\n",
    "        if self.dilation != (1,) * len(self.dilation):\n",
    "            s += ', dilation={dilation}'\n",
    "        if self.output_padding != (0,) * len(self.output_padding):\n",
    "            s += ', output_padding={output_padding}'\n",
    "        if self.groups != 1:\n",
    "            s += ', groups={groups}'\n",
    "        if self.bias is None:\n",
    "            s += ', bias=False'\n",
    "        if self.padding_mode != 'zeros':\n",
    "            s += ', padding_mode={padding_mode}'\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(_ConvNd, self).__setstate__(state)\n",
    "        if not hasattr(self, 'padding_mode'):\n",
    "            self.padding_mode = 'zeros'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(_ConvNd):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1,\n",
    "                 bias=True, padding_mode='zeros'):\n",
    "        kernel_size = _pair(kernel_size)\n",
    "        stride = _pair(stride)\n",
    "        padding = _pair(padding)\n",
    "        dilation = _pair(dilation)\n",
    "        super(Conv2d, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation,\n",
    "            False, _pair(0), groups, bias, padding_mode)\n",
    "        \n",
    "    def conv2d_forward(self, input, weight):\n",
    "        if self.padding_mode == 'circular':\n",
    "            expanded_padding = ((self.padding[1] + 1) // 2, self.padding[1] // 2,\n",
    "                                (self.padding[0] + 1) // 2, self.padding[0] // 2)\n",
    "            return F.conv2d(F.pad(input, expanded_padding, mode='circular'),\n",
    "                            weight, self.bias, self.stride,\n",
    "                            _pair(0), self.dilation, self.groups)\n",
    "        return F.conv2d(input, weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv2d_forward(input, self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomNet __setattr__\n",
      "CustomNet __setattr__\n",
      "CustomNet __setattr__\n",
      "Conv2d __setattr__\n",
      "Conv2d __setattr__\n",
      "Conv2d __setattr__\n",
      "Conv2d __setattr__\n",
      "Conv2d __setattr__\n",
      "Conv2d __setattr__\n",
      "Conv2d __setattr__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Conv2d' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1dc1738404b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-1dc1738404b7>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCustomNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-e135b93f4065>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\u001b[0m\n\u001b[0;32m     10\u001b[0m         super(Conv2d, self).__init__(\n\u001b[0;32m     11\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             False, _pair(0), groups, bias, padding_mode)\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-01589bd530ac>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode)\u001b[0m\n\u001b[0;32m     10\u001b[0m         self.weight = Parameter(torch.Tensor(\n\u001b[0;32m     11\u001b[0m             in_channels, out_channels // groups, *kernel_size))\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Conv2d' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "class CustomNet(Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.conv1 = Conv2d(1, 6, 2)\n",
    "        self.conv2 = Conv2d(6, 16, 3)\n",
    "        self.conv3 = Conv2d(16, 32, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max Pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.avg_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        return x\n",
    "    \n",
    "net = CustomNet()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = Parameter(data=torch.Tensor(1, 6, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00],\n",
       "         [7.0295e+28, 6.1949e-04],\n",
       "         [4.4653e+30, 7.2708e+31],\n",
       "         [3.9172e-02, 4.4628e+30]]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jinma\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\basic\\\\lib\\\\site-packages\\\\torch\\\\__init__.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getfile(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# class Net(nn.Module):\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max Pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('conv1',\n",
       "               Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))),\n",
       "              ('conv2', Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))),\n",
       "              ('fc1', Linear(in_features=576, out_features=120, bias=True)),\n",
       "              ('fc2', Linear(in_features=120, out_features=84, bias=True)),\n",
       "              ('fc3', Linear(in_features=84, out_features=10, bias=True))])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.__dict__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
