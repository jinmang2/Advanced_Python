{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets.txt', 'r', encoding='utf-8') as f:\n",
    "    datasets = f.readlines()\n",
    "    datasets = ''.join(datasets).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [data.split(' ') for data in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [t for doc in docs for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_tokens = list(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2vec = {token:vec for token, vec in zip(uniq_tokens, np.eye(len(uniq_tokens)))}\n",
    "ix2token = {vec.argmax():token for token, vec in \n",
    "            zip(uniq_tokens, np.eye(len(uniq_tokens)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPLM(nn.Module):\n",
    "    \n",
    "    def __init__(self, VOCAB_SIZE, FEATURE_VECTOR_SIZE, HIDDEN_SIZE=32):\n",
    "        super(NPLM, self).__init__()\n",
    "        self.VOCAB_SIZE = VOCAB_SIZE\n",
    "        self.HIDDEN_SIZE = HIDDEN_SIZE\n",
    "        # projection layer (linear)\n",
    "        self.proj_layer = nn.Linear(VOCAB_SIZE, FEATURE_VECTOR_SIZE, bias=False)\n",
    "        # hidden layer (non-linear)\n",
    "        self.hidden_layer = nn.Linear(FEATURE_VECTOR_SIZE, HIDDEN_SIZE, bias=True)\n",
    "        # output layer\n",
    "        self.output_layer = nn.Linear(HIDDEN_SIZE, VOCAB_SIZE, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.proj_layer(x)\n",
    "        x = torch.tanh(self.hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NPLM(len(uniq_tokens), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NPLM(\n",
       "  (proj_layer): Linear(in_features=1009, out_features=100, bias=False)\n",
       "  (hidden_layer): Linear(in_features=100, out_features=32, bias=True)\n",
       "  (output_layer): Linear(in_features=32, out_features=1009, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "torch.Size([100, 1009])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0146, -0.0159,  0.0211,  ...,  0.0264,  0.0148,  0.0240],\n",
       "         [-0.0049, -0.0193, -0.0209,  ..., -0.0087, -0.0274, -0.0091],\n",
       "         [ 0.0309,  0.0227, -0.0100,  ..., -0.0041,  0.0278, -0.0281],\n",
       "         ...,\n",
       "         [ 0.0066,  0.0188,  0.0010,  ..., -0.0053,  0.0271,  0.0142],\n",
       "         [-0.0197,  0.0185,  0.0274,  ...,  0.0155,  0.0085, -0.0012],\n",
       "         [ 0.0251, -0.0215, -0.0268,  ...,  0.0038,  0.0298,  0.0173]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([[-0.0759,  0.0057,  0.0638,  ...,  0.0636, -0.0993,  0.0426],\n",
       "         [-0.0357,  0.0384, -0.0809,  ...,  0.0799, -0.0884,  0.0217],\n",
       "         [-0.0756,  0.0711, -0.0133,  ...,  0.0607,  0.0302, -0.0936],\n",
       "         ...,\n",
       "         [-0.0474, -0.0217, -0.0249,  ...,  0.0639,  0.0803, -0.0315],\n",
       "         [ 0.0881,  0.0205,  0.0734,  ..., -0.0998, -0.0073,  0.0608],\n",
       "         [ 0.0960, -0.0905,  0.0543,  ...,  0.0480,  0.0858,  0.0599]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([-0.0669, -0.0079, -0.0907,  0.0049,  0.0653,  0.0796, -0.0882, -0.0651,\n",
       "         -0.0207, -0.0281,  0.0140,  0.0377,  0.0501,  0.0759,  0.0961,  0.0943,\n",
       "         -0.0411,  0.0943, -0.0258, -0.0997, -0.0247, -0.0448, -0.0758,  0.0278,\n",
       "         -0.0628, -0.0364, -0.0549,  0.0162,  0.0717, -0.0426, -0.0506, -0.0434],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.1343, -0.0690,  0.1357,  ...,  0.0314, -0.0640,  0.0398],\n",
       "         [-0.1545, -0.0628,  0.1179,  ...,  0.0625, -0.1149, -0.1463],\n",
       "         [-0.1530,  0.0430, -0.0364,  ..., -0.0843,  0.0339,  0.0606],\n",
       "         ...,\n",
       "         [ 0.0054,  0.1744,  0.0266,  ...,  0.1483, -0.0810,  0.0501],\n",
       "         [-0.1099, -0.0902,  0.1526,  ...,  0.0117,  0.0882, -0.0867],\n",
       "         [-0.0889, -0.0314, -0.1093,  ..., -0.0781, -0.0323,  0.1659]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([-1.2566e-02, -1.4103e-01, -1.2687e-01,  ..., -1.1272e-01,\n",
       "          8.3476e-05, -5.5280e-02], requires_grad=True)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(np.array(list(map(lambda x: token2vec[x], docs[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.float()\n",
    "outputs = net(inputs.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0467, -0.1317, -0.1607,  ..., -0.1367, -0.0280, -0.0172],\n",
       "        [-0.0395, -0.1245, -0.1563,  ..., -0.1436, -0.0347, -0.0160],\n",
       "        [-0.0469, -0.1398, -0.1474,  ..., -0.1426, -0.0257, -0.0019],\n",
       "        [-0.0523, -0.1185, -0.1538,  ..., -0.1470, -0.0148, -0.0074],\n",
       "        [-0.0486, -0.1191, -0.1553,  ..., -0.1491, -0.0208, -0.0119]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0146, -0.0159,  0.0211,  ...,  0.0264,  0.0148,  0.0240],\n",
       "         [-0.0049, -0.0193, -0.0209,  ..., -0.0087, -0.0274, -0.0091],\n",
       "         [ 0.0309,  0.0227, -0.0100,  ..., -0.0041,  0.0278, -0.0281],\n",
       "         ...,\n",
       "         [ 0.0066,  0.0188,  0.0010,  ..., -0.0053,  0.0271,  0.0142],\n",
       "         [-0.0197,  0.0185,  0.0274,  ...,  0.0155,  0.0085, -0.0012],\n",
       "         [ 0.0251, -0.0215, -0.0268,  ...,  0.0038,  0.0298,  0.0173]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([[-0.0759,  0.0057,  0.0638,  ...,  0.0636, -0.0993,  0.0426],\n",
       "         [-0.0357,  0.0384, -0.0809,  ...,  0.0799, -0.0884,  0.0217],\n",
       "         [-0.0756,  0.0711, -0.0133,  ...,  0.0607,  0.0302, -0.0936],\n",
       "         ...,\n",
       "         [-0.0474, -0.0217, -0.0249,  ...,  0.0639,  0.0803, -0.0315],\n",
       "         [ 0.0881,  0.0205,  0.0734,  ..., -0.0998, -0.0073,  0.0608],\n",
       "         [ 0.0960, -0.0905,  0.0543,  ...,  0.0480,  0.0858,  0.0599]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([-0.0669, -0.0079, -0.0907,  0.0049,  0.0653,  0.0796, -0.0882, -0.0651,\n",
       "         -0.0207, -0.0281,  0.0140,  0.0377,  0.0501,  0.0759,  0.0961,  0.0943,\n",
       "         -0.0411,  0.0943, -0.0258, -0.0997, -0.0247, -0.0448, -0.0758,  0.0278,\n",
       "         -0.0628, -0.0364, -0.0549,  0.0162,  0.0717, -0.0426, -0.0506, -0.0434],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.1343, -0.0690,  0.1357,  ...,  0.0314, -0.0640,  0.0398],\n",
       "         [-0.1545, -0.0628,  0.1179,  ...,  0.0625, -0.1149, -0.1463],\n",
       "         [-0.1530,  0.0430, -0.0364,  ..., -0.0843,  0.0339,  0.0606],\n",
       "         ...,\n",
       "         [ 0.0054,  0.1744,  0.0266,  ...,  0.1483, -0.0810,  0.0501],\n",
       "         [-0.1099, -0.0902,  0.1526,  ...,  0.0117,  0.0882, -0.0867],\n",
       "         [-0.0889, -0.0314, -0.1093,  ..., -0.0781, -0.0323,  0.1659]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([-1.2566e-02, -1.4103e-01, -1.2687e-01,  ..., -1.1272e-01,\n",
       "          8.3476e-05, -5.5280e-02], requires_grad=True)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([781, 781, 781, 781, 781])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(outputs, dim=1).argmax(dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
